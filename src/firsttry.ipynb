{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing, Averaging over all csv-files and Saving the averaged data into new csv-file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.174555Z",
     "start_time": "2024-03-21T12:34:53.412938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ../Daten/averaged_data.csv\n",
      "Found 55 CSV files\n",
      "Found 29 indoor files and 26 outdoor files\n",
      "Saved averaged data to ../Daten/averaged_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "     label  cellStrength  hAccuracyNetwork  vAccuracyNetwork  hAccuracyGPS  \\\n27  Indoor      2.965517         14.174379          1.000000           0.0   \n32  Indoor      1.578947         44.897211          8.357078           0.0   \n31  Indoor      1.071429         16.903071          1.235335           1.9   \n30  Indoor      2.708333         19.186583          2.056563           0.0   \n37  Indoor      2.000000         13.483828          1.246068           0.0   \n\n    vAccuracyGPS  bAccuracyGPS  speedAccuracyGPS  nrSatellitesInView  \\\n27           0.0           0.0               0.0           37.000000   \n32           0.0           0.0               0.0           36.000000   \n31           9.9         178.3               0.9           28.571429   \n30           0.0           0.0               0.0           36.208333   \n37           0.0           0.0               0.0           32.379310   \n\n    nrSatellitesInFix  ...  satellite_cn0_std  satellite_cn0_range  \\\n27                0.0  ...                0.0                  0.0   \n32                0.0  ...                0.0                  0.0   \n31               25.0  ...                0.0                  0.0   \n30                0.0  ...                0.0                  0.0   \n37                0.0  ...                0.0                  0.0   \n\n    bluetooth_rssi_median  bluetooth_rssi_mode  bluetooth_rssi_std  \\\n27             -92.965517           -98.379310           12.799422   \n32             -93.052632           -67.157895           26.664825   \n31             -91.000000           -96.000000           11.244463   \n30             -81.750000           -90.750000           20.431087   \n37             -91.775862           -95.827586           10.434339   \n\n    bluetooth_rssi_range  wifi_rssi_median  wifi_rssi_mode  wifi_rssi_std  \\\n27             51.000000        -72.689655      -73.620690       9.106100   \n32             63.578947        -78.500000      -89.105263      11.209734   \n31             52.000000        -67.000000      -67.000000       7.140650   \n30             47.666667        -78.479167      -89.500000      10.401494   \n37             49.137931        -74.000000      -86.000000      19.372172   \n\n    wifi_rssi_range  \n27        25.068966  \n32        27.789474  \n31        17.000000  \n30        26.833333  \n37        48.000000  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>cellStrength</th>\n      <th>hAccuracyNetwork</th>\n      <th>vAccuracyNetwork</th>\n      <th>hAccuracyGPS</th>\n      <th>vAccuracyGPS</th>\n      <th>bAccuracyGPS</th>\n      <th>speedAccuracyGPS</th>\n      <th>nrSatellitesInView</th>\n      <th>nrSatellitesInFix</th>\n      <th>...</th>\n      <th>satellite_cn0_std</th>\n      <th>satellite_cn0_range</th>\n      <th>bluetooth_rssi_median</th>\n      <th>bluetooth_rssi_mode</th>\n      <th>bluetooth_rssi_std</th>\n      <th>bluetooth_rssi_range</th>\n      <th>wifi_rssi_median</th>\n      <th>wifi_rssi_mode</th>\n      <th>wifi_rssi_std</th>\n      <th>wifi_rssi_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>Indoor</td>\n      <td>2.965517</td>\n      <td>14.174379</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>37.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-92.965517</td>\n      <td>-98.379310</td>\n      <td>12.799422</td>\n      <td>51.000000</td>\n      <td>-72.689655</td>\n      <td>-73.620690</td>\n      <td>9.106100</td>\n      <td>25.068966</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Indoor</td>\n      <td>1.578947</td>\n      <td>44.897211</td>\n      <td>8.357078</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>36.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-93.052632</td>\n      <td>-67.157895</td>\n      <td>26.664825</td>\n      <td>63.578947</td>\n      <td>-78.500000</td>\n      <td>-89.105263</td>\n      <td>11.209734</td>\n      <td>27.789474</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Indoor</td>\n      <td>1.071429</td>\n      <td>16.903071</td>\n      <td>1.235335</td>\n      <td>1.9</td>\n      <td>9.9</td>\n      <td>178.3</td>\n      <td>0.9</td>\n      <td>28.571429</td>\n      <td>25.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-91.000000</td>\n      <td>-96.000000</td>\n      <td>11.244463</td>\n      <td>52.000000</td>\n      <td>-67.000000</td>\n      <td>-67.000000</td>\n      <td>7.140650</td>\n      <td>17.000000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Indoor</td>\n      <td>2.708333</td>\n      <td>19.186583</td>\n      <td>2.056563</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>36.208333</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-81.750000</td>\n      <td>-90.750000</td>\n      <td>20.431087</td>\n      <td>47.666667</td>\n      <td>-78.479167</td>\n      <td>-89.500000</td>\n      <td>10.401494</td>\n      <td>26.833333</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Indoor</td>\n      <td>2.000000</td>\n      <td>13.483828</td>\n      <td>1.246068</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>32.379310</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-91.775862</td>\n      <td>-95.827586</td>\n      <td>10.434339</td>\n      <td>49.137931</td>\n      <td>-74.000000</td>\n      <td>-86.000000</td>\n      <td>19.372172</td>\n      <td>48.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 33 columns</p>\n</div>"
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json \n",
    "from collections import Counter\n",
    "\n",
    "files_directory = '../Daten/firsttry/'\n",
    "\n",
    "averaged_path = '../Daten/averaged_data.csv'\n",
    "\n",
    "\n",
    "# extract the code into a function called preprocess_data so that we can use it later for new data\n",
    "def preprocess_data(directory, averaged_path):\n",
    "    if os.path.exists(averaged_path):\n",
    "        os.remove(averaged_path)\n",
    "        print(f\"Removed {averaged_path}\")\n",
    "\n",
    "    # Get list of CSV files\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "    print(f'Found {len(csv_files)} CSV files')\n",
    "    \n",
    "    # Get nr of files, where name starts with indoor and outdoor\n",
    "    indoor_files = [file for file in csv_files if file.startswith('Indoor')]\n",
    "    outdoor_files = [file for file in csv_files if file.startswith('Outdoor')]\n",
    "    print(f'Found {len(indoor_files)} indoor files and {len(outdoor_files)} outdoor files')\n",
    "    \n",
    "    averaged_data = pd.DataFrame()\n",
    "    \n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(directory + file, sep=';')\n",
    "        # Drop unnecessary columns like timeStampNetwork and timeStampGPS\n",
    "        df = df.drop(columns=['timeStampNetwork', 'timeStampGPS', 'bAccuracyNetwork', 'speedAccuracyNetwork', 'cellType', 'networkLocationType'])\n",
    "        # Remove first x rows and reset begin index to 0\n",
    "        removedRows = 3\n",
    "        df = df.iloc[removedRows:]\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        # Load satellites json\n",
    "        df['satellites'] = df['satellites'].apply(lambda x: json.loads(x))\n",
    "        \n",
    "        '''# Add columns of nr of satellite of each constellation\n",
    "        df['GPS_counts'] = df['satellites'].apply(lambda x: Counter([sat['constellation'] for sat in x if sat['constellation'] == 'GPS']).get('GPS', 0))\n",
    "        \n",
    "        df['BEIDOU_counts'] = df['satellites'].apply(lambda x: Counter([sat['constellation'] for sat in x if sat['constellation'] == 'BEIDOU']).get('BEIDOU', 0))\n",
    "        \n",
    "        df['GALILEO_counts'] = df['satellites'].apply(lambda x: Counter([sat['constellation'] for sat in x if sat['constellation'] == 'GALILEO']).get('GALILEO', 0))\n",
    "        \n",
    "        df['GLONASS_counts'] = df['satellites'].apply(lambda x: Counter([sat['constellation'] for sat in x if sat['constellation'] == 'GLONASS']).get('GLONASS', 0))'''\n",
    "        \n",
    "        # Add cn0 column for easier computation of statistics\n",
    "        df['satellite_cn0'] = df['satellites'].apply(lambda x: [sat['cn0'] for sat in x])\n",
    "        \n",
    "        # Calculate median, mode, variance, standard deviation and range of the satellite cn0\n",
    "        df['satellite_cn0_median'] = df['satellite_cn0'].apply(lambda x: pd.Series(x).median() if not pd.Series(x).empty else 0)\n",
    "        df['satellite_cn0_mode'] = df['satellite_cn0'].apply(lambda x: pd.Series(x).mode()[0] if not pd.Series(x).mode().empty else 0)\n",
    "        df['satellite_cn0_std'] = df['satellite_cn0'].apply(lambda x: pd.Series(x).std() if not pd.Series(x).empty else 0)\n",
    "        df['satellite_cn0_range'] = df['satellite_cn0'].apply(lambda x: pd.Series(x).max() - pd.Series(x).min() if not pd.Series(x).empty else 0)\n",
    "        \n",
    "        # load the bluetooth json and load rssi into a new column\n",
    "        df['bluetoothDevices'] = df['bluetoothDevices'].apply(lambda x: json.loads(x))\n",
    "        df['bluetooth_rssi'] = df['bluetoothDevices'].apply(lambda x: [device['rssi'] for device in x])\n",
    "        \n",
    "         # Calculate statistical figures for the bluetooth devices\n",
    "        df['bluetooth_rssi_median'] = df['bluetooth_rssi'].apply(lambda x: pd.Series(x).median() if not pd.Series(x).empty else 0)\n",
    "        df['bluetooth_rssi_mode'] = df['bluetooth_rssi'].apply(lambda x: pd.Series(x).mode()[0] if not pd.Series(x).mode().empty else 0)\n",
    "        df['bluetooth_rssi_std'] = df['bluetooth_rssi'].apply(lambda x: pd.Series(x).std() if not pd.Series(x).empty else 0)\n",
    "        df['bluetooth_rssi_range'] = df['bluetooth_rssi'].apply(lambda x: pd.Series(x).max() - pd.Series(x).min() if not pd.Series(x).empty else 0)\n",
    "        \n",
    "        # load the wifi json and load rssi into a new column\n",
    "        df['wifiDevices'] = df['wifiDevices'].apply(lambda x: json.loads(x))\n",
    "        df['wifi_rssi'] = df['wifiDevices'].apply(lambda x: [device['level'] for device in x])\n",
    "        \n",
    "         # Calculate statistical figures for the wifi devices\n",
    "        df['wifi_rssi_median'] = df['wifi_rssi'].apply(lambda x: pd.Series(x).median() if not pd.Series(x).empty else 0)\n",
    "        df['wifi_rssi_mode'] = df['wifi_rssi'].apply(lambda x: pd.Series(x).mode()[0] if not pd.Series(x).mode().empty else 0)\n",
    "        df['wifi_rssi_std'] = df['wifi_rssi'].apply(lambda x: pd.Series(x).std() if not pd.Series(x).empty else 0)\n",
    "        df['wifi_rssi_range'] = df['wifi_rssi'].apply(lambda x: pd.Series(x).max() - pd.Series(x).min() if not pd.Series(x).empty else 0)\n",
    "        \n",
    "        # Drop list columns\n",
    "        df.drop(columns=['satellites', 'bluetoothDevices', 'wifiDevices', 'satellite_cn0', 'bluetooth_rssi', 'wifi_rssi'], inplace=True)\n",
    "        \n",
    "         # Average over all columns for numeric values and take the first of non-numeric to have a single row\n",
    "        label = df.iloc[0]['label']\n",
    "        \n",
    "        df.drop(columns=['label'], inplace=True)\n",
    "        \n",
    "        df = df.mean().to_frame().T\n",
    "        \n",
    "        df['label'] = label\n",
    "        \n",
    "        #place label at the beginning\n",
    "        cols = list(df.columns)\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        df = df[cols]\n",
    "        \n",
    "        \n",
    "        # if the nr of satellites is 0, then replace hAccurracyGPS, vAccuracyGPS, speedAccuracyGPS, bAccuracyGPS with NaN\n",
    "        df.loc[df['nrSatellitesInFix'] == 0, ['hAccuracyGPS', 'vAccuracyGPS', 'speedAccuracyGPS', 'bAccuracyGPS']] = 0\n",
    "        \n",
    "        averaged_data = pd.concat([averaged_data, df], ignore_index=True)\n",
    "        \n",
    "        \n",
    "    averaged_data.sort_values(by=['label'], inplace=True)\n",
    "    averaged_data.to_csv(averaged_path, index=False)\n",
    "    print(f'Saved averaged data to {averaged_path}')\n",
    "    return averaged_data\n",
    "\n",
    "averaged_data = preprocess_data(files_directory, averaged_path)\n",
    "averaged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Randomize and Split the Data for Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Randomize the data\n",
    "averaged_data = averaged_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# drop the label column\n",
    "X = averaged_data.drop(columns=['label'], axis=1)\n",
    "Y = averaged_data['label']\n",
    "\n",
    "# Split the data into training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.187360Z",
     "start_time": "2024-03-21T12:34:55.176995Z"
    }
   },
   "execution_count": 318
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of features before selection: 32\n",
      "Nr of features after selection: 16\n",
      "                 feature  importance\n",
      "12    satellite_cn0_mode    0.170669\n",
      "13     satellite_cn0_std    0.150000\n",
      "5      nrSatellitesInFix    0.128789\n",
      "11  satellite_cn0_median    0.125257\n",
      "8              maxCn0GPS    0.120973\n",
      "7             meanCn0GPS    0.119420\n",
      "14   satellite_cn0_range    0.100566\n",
      "6              minCn0GPS    0.029346\n",
      "2           bAccuracyGPS    0.021123\n",
      "3       speedAccuracyGPS    0.014743\n",
      "4     nrSatellitesInView    0.010000\n",
      "9             minCn0Wifi    0.008762\n",
      "1           vAccuracyGPS    0.000185\n",
      "0           hAccuracyGPS    0.000167\n",
      "10            maxCn0Wifi    0.000000\n",
      "15         wifi_rssi_std    0.000000\n",
      "Cross-validation scores: [0.875 1.    1.    1.    1.   ]\n",
      "Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest Classifier with regularization\n",
    "clf = RandomForestClassifier(random_state=42, max_depth=10, min_samples_leaf=5)\n",
    "\n",
    "# Print the nr of features before selection\n",
    "print(f'Nr of features before selection: {X_train.shape[1]}')\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectFromModel(clf,  threshold=0.01).fit(X_train, Y_train)\n",
    "\n",
    "# Transform the data to create a new dataset containing only the most important features\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Print the nr of features after selection\n",
    "print(f'Nr of features after selection: {X_train.shape[1]}')\n",
    "\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(clf, X_train, Y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.568108Z",
     "start_time": "2024-03-21T12:34:55.188100Z"
    }
   },
   "execution_count": 319
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Decision Trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"from sklearn.tree import export_graphviz\\nimport pydot\\n\\n# Export as dot and png file\\nfor i, tree in enumerate(clf.estimators_):\\n    export_graphviz(tree, out_file=f'tree{i}.dot', feature_names = X.columns, rounded = True, precision = 1)\\n    (graph,) = pydot.graph_from_dot_file(f'tree{i}.dot')\\n    graph.write_png(f'tree{i}.png')\\n    \\n#combine all trees into the decision forest\\nfrom PIL import Image\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nimages = [Image.open(f'tree{i}.png') for i in range(10)]\\nwidths, heights = zip(*(i.size for i in images))\\n\\ntotal_width = sum(widths)\\nmax_height = max(heights)\\n\\nnew_im = Image.new('RGB', (total_width, max_height))\\n\\nx_offset = 0\\nfor im in images:\\n  new_im.paste(im, (x_offset,0))\\n  x_offset += im.size[0]\\n  \\nnew_im.save('decision_forest.png')\\nplt.imshow(np.asarray(new_im))\\nplt.show()\""
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizing the all decision trees\n",
    "'''from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "# Export as dot and png file\n",
    "for i, tree in enumerate(clf.estimators_):\n",
    "    export_graphviz(tree, out_file=f'tree{i}.dot', feature_names = X.columns, rounded = True, precision = 1)\n",
    "    (graph,) = pydot.graph_from_dot_file(f'tree{i}.dot')\n",
    "    graph.write_png(f'tree{i}.png')\n",
    "    \n",
    "#combine all trees into the decision forest\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = [Image.open(f'tree{i}.png') for i in range(10)]\n",
    "widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "total_width = sum(widths)\n",
    "max_height = max(heights)\n",
    "\n",
    "new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "x_offset = 0\n",
    "for im in images:\n",
    "  new_im.paste(im, (x_offset,0))\n",
    "  x_offset += im.size[0]\n",
    "  \n",
    "new_im.save('decision_forest.png')\n",
    "plt.imshow(np.asarray(new_im))\n",
    "plt.show()'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.572386Z",
     "start_time": "2024-03-21T12:34:55.569563Z"
    }
   },
   "execution_count": 320
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the Feature Importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature  importance\n",
      "12    satellite_cn0_mode    0.170669\n",
      "13     satellite_cn0_std    0.150000\n",
      "5      nrSatellitesInFix    0.128789\n",
      "11  satellite_cn0_median    0.125257\n",
      "8              maxCn0GPS    0.120973\n",
      "7             meanCn0GPS    0.119420\n",
      "14   satellite_cn0_range    0.100566\n",
      "6              minCn0GPS    0.029346\n",
      "2           bAccuracyGPS    0.021123\n",
      "3       speedAccuracyGPS    0.014743\n",
      "4     nrSatellitesInView    0.010000\n",
      "9             minCn0Wifi    0.008762\n",
      "1           vAccuracyGPS    0.000185\n",
      "0           hAccuracyGPS    0.000167\n",
      "10            maxCn0Wifi    0.000000\n",
      "15         wifi_rssi_std    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the most important features and print their according importance\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "# Print feature importances of the selected features\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': selected_features, 'importance': feature_importances})\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "print(feature_importances)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.580487Z",
     "start_time": "2024-03-21T12:34:55.573207Z"
    }
   },
   "execution_count": 321
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model and tryout the model with new data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ../Daten/random_forest_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "model_path = '../Daten/random_forest_classifier.joblib'\n",
    "joblib.dump(clf, model_path)\n",
    "print(f'Saved model to {model_path}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.603914Z",
     "start_time": "2024-03-21T12:34:55.581450Z"
    }
   },
   "execution_count": 322
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model with new data in validation folder in this notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ../Daten/validation_averaged_data.csv\n",
      "Found 4 CSV files\n",
      "Found 2 indoor files and 2 outdoor files\n",
      "Saved averaged data to ../Daten/validation_averaged_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehmettasdemir/miniconda3/envs/IODataProject/lib/python3.8/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 32 features, but RandomForestClassifier is expecting 16 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[323], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m validation_averaged_data \u001B[38;5;241m=\u001B[39m preprocess_data(validation_files_directory, validation_averaged_path)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Predict the labels of the validation data\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m validation_predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalidation_averaged_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#print label and the corresponding prediction\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m label, prediction \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(validation_averaged_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m], validation_predictions):\n",
      "File \u001B[0;32m~/miniconda3/envs/IODataProject/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:823\u001B[0m, in \u001B[0;36mForestClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    803\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;124;03m    Predict class for X.\u001B[39;00m\n\u001B[1;32m    805\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;124;03m        The predicted classes.\u001B[39;00m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 823\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    825\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    826\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39margmax(proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/IODataProject/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:865\u001B[0m, in \u001B[0;36mForestClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    863\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    864\u001B[0m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[0;32m--> 865\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[1;32m    868\u001B[0m n_jobs, _, _ \u001B[38;5;241m=\u001B[39m _partition_estimators(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[0;32m~/miniconda3/envs/IODataProject/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:599\u001B[0m, in \u001B[0;36mBaseForest._validate_X_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    596\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    597\u001B[0m \u001B[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001B[39;00m\n\u001B[1;32m    598\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 599\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc):\n\u001B[1;32m    601\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/IODataProject/lib/python3.8/site-packages/sklearn/base.py:625\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 625\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/miniconda3/envs/IODataProject/lib/python3.8/site-packages/sklearn/base.py:414\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[0;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    415\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    417\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: X has 32 features, but RandomForestClassifier is expecting 16 features as input."
     ]
    }
   ],
   "source": [
    "validation_files_directory = '../Daten/validation/'\n",
    "\n",
    "validation_averaged_path = '../Daten/validation_averaged_data.csv'\n",
    "\n",
    "model_path = '../Daten/random_forest_classifier.joblib'\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "validation_averaged_data = preprocess_data(validation_files_directory, validation_averaged_path)\n",
    "\n",
    "# Predict the labels of the validation data\n",
    "validation_predictions = model.predict(validation_averaged_data.drop(columns=['label']))\n",
    "\n",
    "#print label and the corresponding prediction\n",
    "for label, prediction in zip(validation_averaged_data['label'], validation_predictions):\n",
    "    print(f'Label: {label}, Prediction: {prediction}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T12:34:55.767428Z",
     "start_time": "2024-03-21T12:34:55.604634Z"
    }
   },
   "execution_count": 323
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
